{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd2e485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "2       430632  ...                      NO              34650         7700   \n",
       "3       608117  ...                      NO              63400         6340   \n",
       "4       610706  ...                      NO               6500         1300   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "2           3850         23100      Dodge         RAM      2007   \n",
       "3           6340         50720  Chevrolet       Tahoe      2014   \n",
       "4            650          4550     Accura         RSX      2009   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "2              N  NaN  \n",
       "3              Y  NaN  \n",
       "4              N  NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets start by reading in the csv file and printing out the first few lines\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('insurance_claims.csv')\n",
    "\n",
    "\n",
    "df.head (5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fccc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets take a look at the number of rows and columns in the dataframe\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4040ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
       "       'policy_state', 'policy_csl', 'policy_deductable',\n",
       "       'policy_annual_premium', 'umbrella_limit', 'insured_zip', 'insured_sex',\n",
       "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
       "       'insured_relationship', 'capital-gains', 'capital-loss',\n",
       "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
       "       'authorities_contacted', 'incident_state', 'incident_city',\n",
       "       'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported', '_c39'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f0fa82",
   "metadata": {},
   "source": [
    "# 📊 Insurance Claims Dataset: Field Explanations\n",
    "\n",
    "\"\"\"\n",
    "🔹 Customer & Policy Information\n",
    "- months_as_customer: Number of months the person has been a customer\n",
    "- age: Age of the insured person\n",
    "- policy_number: Unique identifier for the policy\n",
    "- policy_bind_date: Date when the policy was issued/bound\n",
    "- policy_state: State where the policy was issued\n",
    "- policy_csl: Combined single limit of liability coverage\n",
    "- policy_deductable: Deductible amount for the policy\n",
    "- policy_annual_premium: Annual premium paid for the policy\n",
    "- umbrella_limit: Maximum coverage limit of the umbrella policy\n",
    "\n",
    "🔹 Insured (Customer) Demographics\n",
    "- insured_zip: ZIP code of the insured\n",
    "- insured_sex: Gender of the insured\n",
    "- insured_education_level: Highest education level of the insured\n",
    "- insured_occupation: Occupation of the insured\n",
    "- insured_hobbies: Hobbies of the insured\n",
    "- insured_relationship: Relationship status of the insured\n",
    "\n",
    "🔹 Financial Information\n",
    "- capital-gains: Capital gains reported by the insured\n",
    "- capital-loss: Capital losses reported by the insured\n",
    "Note:\n",
    "\n",
    " When your car is damaged or totaled, its value often drops.\n",
    " If the car’s market value after the accident is less than what you originally paid, that’s an economic loss (a capital loss in broader financial language).\n",
    "\n",
    "Example: You bought a car for $25,000, and before the accident it was worth $15,000. After a collision, insurance values it at $10,000 and pays you that amount.\n",
    "\n",
    "🔹 Incident Details\n",
    "- incident_date: Date of the reported incident\n",
    "- incident_type: Type of incident (e.g., theft, collision, fire)\n",
    "- collision_type: Type of collision (if applicable)\n",
    "- incident_severity: Severity of the incident (e.g., minor, major, total loss)\n",
    "- authorities_contacted: Which authorities were contacted (police, fire dept.)\n",
    "- incident_state: State where the incident occurred\n",
    "- incident_city: City where the incident occurred\n",
    "- incident_location: Specific location/address of the incident\n",
    "- incident_hour_of_the_day: Hour of the day when the incident occurred\n",
    "\n",
    "🔹 Incident Outcomes\n",
    "- number_of_vehicles_involved: How many vehicles were part of the incident\n",
    "- property_damage: Whether there was property damage (Y/N/Unknown)\n",
    "- bodily_injuries: Number of bodily injuries reported\n",
    "- witnesses: Number of witnesses present\n",
    "- police_report_available: Whether a police report was available (Y/N/Unknown)\n",
    "\n",
    "🔹 Claim Information\n",
    "- total_claim_amount: Total claim amount requested/paid\n",
    "- injury_claim: Claim amount related to injuries\n",
    "- property_claim: Claim amount related to property damage\n",
    "- vehicle_claim: Claim amount related to vehicle damage\n",
    "\n",
    "🔹 Vehicle Information\n",
    "- auto_make: Make of the insured’s vehicle\n",
    "- auto_model: Model of the insured’s vehicle\n",
    "- auto_year: Year of the insured’s vehicle\n",
    "\n",
    "🔹 Fraud Indicator\n",
    "- fraud_reported: Whether the claim was flagged/reported as fraud (Y/N)\n",
    "\n",
    "🔹 Miscellaneous\n",
    "- _c39: Extra/unidentified column (may be an artifact from CSV export)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc661ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>203.954000</td>\n",
       "      <td>38.948000</td>\n",
       "      <td>546238.648000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1256.406150</td>\n",
       "      <td>1.101000e+06</td>\n",
       "      <td>501214.488000</td>\n",
       "      <td>25126.100000</td>\n",
       "      <td>-26793.700000</td>\n",
       "      <td>11.644000</td>\n",
       "      <td>1.83900</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>1.487000</td>\n",
       "      <td>52761.94000</td>\n",
       "      <td>7433.420000</td>\n",
       "      <td>7399.570000</td>\n",
       "      <td>37928.950000</td>\n",
       "      <td>2005.103000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.113174</td>\n",
       "      <td>9.140287</td>\n",
       "      <td>257063.005276</td>\n",
       "      <td>611.864673</td>\n",
       "      <td>244.167395</td>\n",
       "      <td>2.297407e+06</td>\n",
       "      <td>71701.610941</td>\n",
       "      <td>27872.187708</td>\n",
       "      <td>28104.096686</td>\n",
       "      <td>6.951373</td>\n",
       "      <td>1.01888</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>1.111335</td>\n",
       "      <td>26401.53319</td>\n",
       "      <td>4880.951853</td>\n",
       "      <td>4824.726179</td>\n",
       "      <td>18886.252893</td>\n",
       "      <td>6.015861</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>100804.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>433.330000</td>\n",
       "      <td>-1.000000e+06</td>\n",
       "      <td>430104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-111100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1995.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>335980.250000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1089.607500</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>448404.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-51500.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41812.50000</td>\n",
       "      <td>4295.000000</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>30292.500000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>533135.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1257.200000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>466445.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23250.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58055.00000</td>\n",
       "      <td>6775.000000</td>\n",
       "      <td>6750.000000</td>\n",
       "      <td>42100.000000</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>276.250000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>759099.750000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1415.695000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>603251.000000</td>\n",
       "      <td>51025.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>70592.50000</td>\n",
       "      <td>11305.000000</td>\n",
       "      <td>10885.000000</td>\n",
       "      <td>50822.500000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>479.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>999435.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2047.590000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>620962.000000</td>\n",
       "      <td>100500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>114920.00000</td>\n",
       "      <td>21450.000000</td>\n",
       "      <td>23670.000000</td>\n",
       "      <td>79560.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_as_customer          age  policy_number  policy_deductable  \\\n",
       "count         1000.000000  1000.000000    1000.000000        1000.000000   \n",
       "mean           203.954000    38.948000  546238.648000        1136.000000   \n",
       "std            115.113174     9.140287  257063.005276         611.864673   \n",
       "min              0.000000    19.000000  100804.000000         500.000000   \n",
       "25%            115.750000    32.000000  335980.250000         500.000000   \n",
       "50%            199.500000    38.000000  533135.000000        1000.000000   \n",
       "75%            276.250000    44.000000  759099.750000        2000.000000   \n",
       "max            479.000000    64.000000  999435.000000        2000.000000   \n",
       "\n",
       "       policy_annual_premium  umbrella_limit    insured_zip  capital-gains  \\\n",
       "count            1000.000000    1.000000e+03    1000.000000    1000.000000   \n",
       "mean             1256.406150    1.101000e+06  501214.488000   25126.100000   \n",
       "std               244.167395    2.297407e+06   71701.610941   27872.187708   \n",
       "min               433.330000   -1.000000e+06  430104.000000       0.000000   \n",
       "25%              1089.607500    0.000000e+00  448404.500000       0.000000   \n",
       "50%              1257.200000    0.000000e+00  466445.500000       0.000000   \n",
       "75%              1415.695000    0.000000e+00  603251.000000   51025.000000   \n",
       "max              2047.590000    1.000000e+07  620962.000000  100500.000000   \n",
       "\n",
       "        capital-loss  incident_hour_of_the_day  number_of_vehicles_involved  \\\n",
       "count    1000.000000               1000.000000                   1000.00000   \n",
       "mean   -26793.700000                 11.644000                      1.83900   \n",
       "std     28104.096686                  6.951373                      1.01888   \n",
       "min   -111100.000000                  0.000000                      1.00000   \n",
       "25%    -51500.000000                  6.000000                      1.00000   \n",
       "50%    -23250.000000                 12.000000                      1.00000   \n",
       "75%         0.000000                 17.000000                      3.00000   \n",
       "max         0.000000                 23.000000                      4.00000   \n",
       "\n",
       "       bodily_injuries    witnesses  total_claim_amount  injury_claim  \\\n",
       "count      1000.000000  1000.000000          1000.00000   1000.000000   \n",
       "mean          0.992000     1.487000         52761.94000   7433.420000   \n",
       "std           0.820127     1.111335         26401.53319   4880.951853   \n",
       "min           0.000000     0.000000           100.00000      0.000000   \n",
       "25%           0.000000     1.000000         41812.50000   4295.000000   \n",
       "50%           1.000000     1.000000         58055.00000   6775.000000   \n",
       "75%           2.000000     2.000000         70592.50000  11305.000000   \n",
       "max           2.000000     3.000000        114920.00000  21450.000000   \n",
       "\n",
       "       property_claim  vehicle_claim    auto_year  _c39  \n",
       "count     1000.000000    1000.000000  1000.000000   0.0  \n",
       "mean      7399.570000   37928.950000  2005.103000   NaN  \n",
       "std       4824.726179   18886.252893     6.015861   NaN  \n",
       "min          0.000000      70.000000  1995.000000   NaN  \n",
       "25%       4445.000000   30292.500000  2000.000000   NaN  \n",
       "50%       6750.000000   42100.000000  2005.000000   NaN  \n",
       "75%      10885.000000   50822.500000  2010.000000   NaN  \n",
       "max      23670.000000   79560.000000  2015.000000   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get a few summary statistics of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68a03ab",
   "metadata": {},
   "source": [
    "# 📊 Insurance Claims — Summary Statistics (Numeric Features)\n",
    "\n",
    "Here are the descriptive statistics from the dataset (n = 1000 claims):\n",
    "\n",
    "---\n",
    "\n",
    "## 📅 Customer & Policy\n",
    "| Variable | Count | Mean | Std | Min | 25% | 50% | 75% | Max |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
    "| `months_as_customer` | 1000 | 203.95 | 115.11 | 0 | 115.75 | 199.5 | 276.25 | 479 |\n",
    "| `age` | 1000 | 38.95 | 9.14 | 19 | 32 | 38 | 44 | 64 |\n",
    "| `policy_number` | 1000 | 546,238.65 | 257,063.01 | 100,804 | 335,980 | 533,135 | 759,100 | 999,435 |\n",
    "| `policy_deductable` | 1000 | 1,136.00 | 611.86 | 500 | 500 | 1000 | 2000 | 2000 |\n",
    "| `policy_annual_premium` | 1000 | 1,256.41 | 244.17 | 433.33 | 1089.61 | 1257.20 | 1415.70 | 2047.59 |\n",
    "| `umbrella_limit` | 1000 | 1.10e6 | 2.30e6 | -1.00e6 | 0 | 0 | 0 | 1.00e7 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🏦 Financials\n",
    "| Variable | Count | Mean | Std | Min | 25% | 50% | 75% | Max |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
    "| `insured_zip` | 1000 | 501,214.49 | 71,701.61 | 430,104 | 448,405 | 466,446 | 603,251 | 620,962 |\n",
    "| `capital-gains` | 1000 | 25,126.10 | 27,872.19 | 0 | 0 | 0 | 51,025 | 100,500 |\n",
    "| `capital-loss` | 1000 | -26,793.70 | 28,104.10 | -111,100 | -51,500 | -23,250 | 0 | 0 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🚨 Incident Details\n",
    "| Variable | Count | Mean | Std | Min | 25% | 50% | 75% | Max |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
    "| `incident_hour_of_the_day` | 1000 | 11.64 | 6.95 | 0 | 6 | 12 | 17 | 23 |\n",
    "| `number_of_vehicles_involved` | 1000 | 1.84 | 1.02 | 1 | 1 | 1 | 3 | 4 |\n",
    "| `bodily_injuries` | 1000 | 0.99 | 0.82 | 0 | 0 | 1 | 2 | 2 |\n",
    "| `witnesses` | 1000 | 1.49 | 1.11 | 0 | 1 | 1 | 2 | 3 |\n",
    "\n",
    "---\n",
    "\n",
    "## 💰 Claims\n",
    "| Variable | Count | Mean | Std | Min | 25% | 50% | 75% | Max |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
    "| `total_claim_amount` | 1000 | 52,761.94 | 26,401.53 | 100 | 41,813 | 58,055 | 70,593 | 114,920 |\n",
    "| `injury_claim` | 1000 | 7,433.42 | 4,880.95 | 0 | 4,295 | 6,775 | 11,305 | 21,450 |\n",
    "| `property_claim` | 1000 | 7,399.57 | 4,824.73 | 0 | 4,445 | 6,750 | 10,885 | 23,670 |\n",
    "| `vehicle_claim` | 1000 | 37,928.95 | 18,886.25 | 70 | 30,293 | 42,100 | 50,823 | 79,560 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🚗 Vehicle\n",
    "| Variable | Count | Mean | Std | Min | 25% | 50% | 75% | Max |\n",
    "|---|---:|---:|---:|---:|---:|---:|---:|---:|\n",
    "| `auto_year` | 1000 | 2005.10 | 6.02 | 1995 | 2000 | 2005 | 2010 | 2015 |\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ Notes\n",
    "- `umbrella_limit` has extreme outliers (min = -1,000,000, max = 10,000,000).  \n",
    "- `capital-gains` and `capital-loss` are highly skewed (lots of 0s).  \n",
    "- Claims data (`injury_claim`, `property_claim`, `vehicle_claim`) have heavy right tails — large maximums compared to median.  \n",
    "- `_c39` column contains no values → candidate for drop.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd6bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.000000e+03\n",
      "mean     1.101000e+06\n",
      "std      2.297407e+06\n",
      "min     -1.000000e+06\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      1.000000e+07\n",
      "Name: umbrella_limit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Lets start by dropping any empty columns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#lets drop the _c39 column as it is completely empty\n",
    "df = df.drop(columns=['_c39'])\n",
    "\n",
    "# umbrella_limit: inspect and cap / flag\n",
    "print(df['umbrella_limit'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15c0f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umbrella_limit\n",
      " 0           798\n",
      " 6000000      57\n",
      " 5000000      46\n",
      " 4000000      39\n",
      " 7000000      29\n",
      " 3000000      12\n",
      " 8000000       8\n",
      " 9000000       5\n",
      " 2000000       3\n",
      " 10000000      2\n",
      "-1000000       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#lets further inspect the umbrella_limit column\n",
    "print(df['umbrella_limit'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192cc2b",
   "metadata": {},
   "source": [
    "\n",
    "Umbrella insurance provides EXTRA liability coverage\n",
    "on top of existing policies (like auto or homeowners).\n",
    "It \"kicks in\" when those underlying policy limits are reached.\n",
    "\n",
    "🔹 Example:\n",
    "- Auto insurance liability limit: $250,000\n",
    "- Accident causes damages: $1,000,000\n",
    "\n",
    "Auto insurance pays first $250,000.\n",
    "Umbrella policy pays the remainder up to its umbrella limit.\n",
    "\n",
    "So, if the umbrella limit is $1,000,000:\n",
    "- Auto covers: $250,000\n",
    "- Umbrella covers: $750,000\n",
    "- Total covered: $1,000,000\n",
    "- You’re protected from paying out of pocket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e6332",
   "metadata": {},
   "source": [
    "798/1000 rows have umbrella_limit = 0 → most policies have no umbrella coverage.\n",
    "\n",
    "Many repeated large values (2–10M) suggest a set of standard coverage tiers, not continuous measurements.\n",
    "\n",
    "One row has -1,000,000 → looks like a sentinel / data error (treat as missing).\n",
    "\n",
    "Mean and std are dominated by the few large tiers, so raw mean is not representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2567f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy number(s) with umbrella_limit = NaN:\n",
      "[526039]\n"
     ]
    }
   ],
   "source": [
    "#looks like one record has a negative value, which is impossible\n",
    "#lets replace it with a NaN value\n",
    "# ensure numeric (coerce any stray strings to NaN)\n",
    "df['umbrella_limit'] = pd.to_numeric(df['umbrella_limit'], errors='coerce')\n",
    "\n",
    "# replace negative sentinel values with NaN (keep zero as valid \"no coverage\")\n",
    "df.loc[df['umbrella_limit'] < 0, 'umbrella_limit'] = np.nan\n",
    "\n",
    "\n",
    "# show the rows where umbrella_limit is NaN (full rows)\n",
    "print(\"Policy number(s) with umbrella_limit = NaN:\")\n",
    "print(df.loc[df['umbrella_limit'].isna(), 'policy_number'].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dcefdb",
   "metadata": {},
   "source": [
    "For policy number 526039, instead of having a negative value, which is not possible for Umbrella Coverage, it now has the value NaN in that column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5089db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      1000.000000\n",
      "mean      25126.100000\n",
      "std       27872.187708\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%       51025.000000\n",
      "max      100500.000000\n",
      "Name: capital-gains, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Now lets take a look at the capital-gains column\n",
    "print(df['capital-gains'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8c3d892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-gains\n",
      "0        508\n",
      "46300      5\n",
      "51500      4\n",
      "68500      4\n",
      "55600      3\n",
      "        ... \n",
      "36700      1\n",
      "54900      1\n",
      "69200      1\n",
      "48800      1\n",
      "50300      1\n",
      "Name: count, Length: 338, dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [months_as_customer, age, policy_number, policy_bind_date, policy_state, policy_csl, policy_deductable, policy_annual_premium, umbrella_limit, insured_zip, insured_sex, insured_education_level, insured_occupation, insured_hobbies, insured_relationship, capital-gains, capital-loss, incident_date, incident_type, collision_type, incident_severity, authorities_contacted, incident_state, incident_city, incident_location, incident_hour_of_the_day, number_of_vehicles_involved, property_damage, bodily_injuries, witnesses, police_report_available, total_claim_amount, injury_claim, property_claim, vehicle_claim, auto_make, auto_model, auto_year, fraud_reported]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 39 columns]\n",
      "Number of NaN values in capital-gains column: 0\n"
     ]
    }
   ],
   "source": [
    "#looks like there are a lot of 0 values, which is possible\n",
    "#lets take a look at the value counts\n",
    "print(df['capital-gains'].value_counts())\n",
    "\n",
    "#Lots of 0 values, which is possible\n",
    "#lets check for negative values, which are not possible\n",
    "print(df.loc[df['capital-gains'] < 0])\n",
    "\n",
    "\n",
    "#No negative values found, so we are good here\n",
    "\n",
    "#next question is what to do with the NaN values\n",
    "#lets see how many NaN values there are\n",
    "print(\"Number of NaN values in capital-gains column:\", df['capital-gains'].isna().sum())\n",
    "\n",
    "\n",
    "#There are no NaN values in this column, so we are good here, however, the data is highly skewed with a few very high values\n",
    "#we will leave it as is for now, but we may want to consider capping the high values later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542300d1",
   "metadata": {},
   "source": [
    "# 💰 Capital Gains Column Analysis\n",
    "\n",
    "The 'capital-gains' column represents reported capital gains\n",
    "associated with the insured customer.\n",
    "\n",
    "📊 Distribution Summary:\n",
    "- Most customers report **0** capital gains (508 occurrences).\n",
    "- A small number of customers report positive gains at various levels:\n",
    "    • 46,300 → 5 customers\n",
    "    • 51,500 → 4 customers\n",
    "    • 68,500 → 4 customers\n",
    "    • 55,600 → 3 customers\n",
    "    • ... and many other values with only 1 occurrence.\n",
    "- In total, there are **338 unique values** of capital gains.\n",
    "\n",
    "🔎 Data Quality:\n",
    "- No missing values (NaN count = 0).\n",
    "- Skewed distribution (heavily concentrated at 0).\n",
    "- Long-tail effect: many unique positive values but low frequency.\n",
    "\n",
    "✅ Implications for Analysis:\n",
    "- Most insured individuals don’t report capital gains.\n",
    "- Customers with large gains are rare but may be important outliers.\n",
    "- This feature could have predictive power in fraud detection:\n",
    "    • A sudden spike in unusual gains could correlate with suspicious activity.\n",
    "    • Encoding should consider the extreme imbalance (0 vs. non-0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a70413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      1000.000000\n",
      "mean     -26793.700000\n",
      "std       28104.096686\n",
      "min     -111100.000000\n",
      "25%      -51500.000000\n",
      "50%      -23250.000000\n",
      "75%           0.000000\n",
      "max           0.000000\n",
      "Name: capital-loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Now lets take a look at the capital-loss column\n",
    "print(df['capital-loss'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880bd952",
   "metadata": {},
   "source": [
    "# 📊 Capital-Loss Column Analysis (Vehicle Insurance Claims Dataset)\n",
    "\n",
    "# Summary Statistics\n",
    " count    → 1000 (all rows have values)\n",
    "\n",
    " mean     → -26,793 (average claim shows ~27K in losses)\n",
    "\n",
    " std      → 28,104 (very high variability in losses)\n",
    "\n",
    " min      → -111,100 (largest recorded loss)\n",
    "\n",
    " 25%      → -51,500 (25% of claims lost more than 51.5K)\n",
    "\n",
    " 50%      → -23,250 (median loss ~23K)\n",
    "\n",
    " 75%      → 0 (25% of claims report no capital loss)\n",
    "\n",
    " max      → 0 (no positive values; only losses or none)\n",
    "\n",
    "# ✅ Interpretation:\n",
    "- Values are strictly negative or zero.\n",
    "- Negative values = reduction in value of the vehicle/property not offset by insurance.\n",
    "- Zeros = either fully covered claims or cases where no capital loss applied.\n",
    "- The distribution is skewed: many claims at 0, some with very large negative losses.\n",
    "- Extreme negative values likely correspond to severe accidents/total losses (e.g., expensive vehicles or fleets). These exteremes will likely be a good idea for me to take a look at further in the EDA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1113859e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    collision_type property_damage police_report_available\n",
      "0   Side Collision             YES                     YES\n",
      "1          Unknown         Unknown                 Unknown\n",
      "2   Rear Collision              NO                      NO\n",
      "3  Front Collision         Unknown                      NO\n",
      "4          Unknown              NO                      NO\n"
     ]
    }
   ],
   "source": [
    "# Replace \"?\" with \"Unknown\" in selected columns\n",
    "cols_to_fix = ['collision_type', 'property_damage', 'police_report_available']\n",
    "df[cols_to_fix] = df[cols_to_fix].replace(\"?\", \"Unknown\")\n",
    "\n",
    "# Check the fix\n",
    "print(df[cols_to_fix].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e477a1c",
   "metadata": {},
   "source": [
    "### Replacing \"?\" with \"Unknown\"\n",
    "\n",
    "In several columns, missing or unclear values are represented with `\"?\"`.  \n",
    "To improve readability and ensure consistent categorical handling, we replace all `\"?\"` entries with `\"Unknown\"` in the following columns:\n",
    "\n",
    "- **collision_type**  \n",
    "- **property_damage**  \n",
    "- **police_report_available**  \n",
    "\n",
    "This makes the dataset cleaner and avoids confusion during analysis or visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e916c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  policy_csl  Policy_Csl_Person  Policy_Csl_Accident\n",
      "0    250/500                250                  500\n",
      "1    250/500                250                  500\n",
      "2    100/300                100                  300\n",
      "3    250/500                250                  500\n",
      "4   500/1000                500                 1000\n"
     ]
    }
   ],
   "source": [
    "# Split 'Policy Csl' into two new columns\n",
    "df[['Policy_Csl_Person', 'Policy_Csl_Accident']] = df['policy_csl'].str.split('/', expand=True)\n",
    "\n",
    "# Convert to numeric for analysis\n",
    "df['Policy_Csl_Person'] = pd.to_numeric(df['Policy_Csl_Person'])\n",
    "df['Policy_Csl_Accident'] = pd.to_numeric(df['Policy_Csl_Accident'])\n",
    "\n",
    "# Preview\n",
    "print(df[['policy_csl', 'Policy_Csl_Person', 'Policy_Csl_Accident']].head())\n",
    "\n",
    "#lets drop the original policy_csl column\n",
    "df = df.drop(columns=['policy_csl'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7488d23",
   "metadata": {},
   "source": [
    "### Splitting the 'Policy Csl' Column\n",
    "\n",
    "The `policy_csl` column contains compound values (e.g., `250/500`) that represent coverage limits.  \n",
    "To make analysis easier, we split this column into two new numeric fields:  \n",
    "\n",
    "- **Policy_Csl_Person** → coverage per person  \n",
    "- **Policy_Csl_Accident** → coverage per accident  \n",
    "\n",
    "After splitting, we drop the original `policy_csl` column since it is redundant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "144df20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Number of missing values in each column:\n",
      "months_as_customer              0\n",
      "age                             0\n",
      "policy_number                   0\n",
      "policy_bind_date                0\n",
      "policy_state                    0\n",
      "policy_deductable               0\n",
      "policy_annual_premium           0\n",
      "umbrella_limit                  1\n",
      "insured_zip                     0\n",
      "insured_sex                     0\n",
      "insured_education_level         0\n",
      "insured_occupation              0\n",
      "insured_hobbies                 0\n",
      "insured_relationship            0\n",
      "capital-gains                   0\n",
      "capital-loss                    0\n",
      "incident_date                   0\n",
      "incident_type                   0\n",
      "collision_type                  0\n",
      "incident_severity               0\n",
      "authorities_contacted          91\n",
      "incident_state                  0\n",
      "incident_city                   0\n",
      "incident_location               0\n",
      "incident_hour_of_the_day        0\n",
      "number_of_vehicles_involved     0\n",
      "property_damage                 0\n",
      "bodily_injuries                 0\n",
      "witnesses                       0\n",
      "police_report_available         0\n",
      "total_claim_amount              0\n",
      "injury_claim                    0\n",
      "property_claim                  0\n",
      "vehicle_claim                   0\n",
      "auto_make                       0\n",
      "auto_model                      0\n",
      "auto_year                       0\n",
      "fraud_reported                  0\n",
      "Policy_Csl_Person               0\n",
      "Policy_Csl_Accident             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Lets first see if we see any duplicate rows\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "#There are no duplicate rows, so we are good here\n",
    "\n",
    "#Next, lets check for any missing values in the dataframe\n",
    "print(\"Number of missing values in each column:\")\n",
    "print(df.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14b7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authorities_contacted\n",
      "Police       292\n",
      "Fire         223\n",
      "Other        198\n",
      "Ambulance    196\n",
      "NaN           91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#It seems that authorities_contacted field has a lot of missing values\n",
    "#lets take a look at the value counts for this column\n",
    "print(df['authorities_contacted'].value_counts(dropna=False))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08480c53",
   "metadata": {},
   "source": [
    "#It seems that most of the values are NaN, which is possible if no authorities were contacted\n",
    "#we will leave it as is for now\n",
    "\n",
    "# 🚓 Authorities Contacted Column\n",
    "\n",
    "\"\"\"\n",
    "It seems that most of the values in the 'authorities_contacted' column are NaN.  \n",
    "This makes sense, as many incidents may not have required contacting any authorities.  \n",
    "\n",
    "✅ Decision:\n",
    "We will leave the NaN values as they are for now, since:\n",
    "- NaN here may carry meaningful information (e.g., \"no authorities contacted\").\n",
    "- Dropping or imputing could remove that signal. I'll need to look further into whether NaN is the same as no authorities contacted. \n",
    "- At this time, based off of analysis, I am going to treat NaN as no authorities contacted, and change the field to no authorities contacted\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee83fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authorities_contacted\n",
      "Police                      292\n",
      "Fire                        223\n",
      "Other                       198\n",
      "Ambulance                   196\n",
      "No Authorities Contacted     91\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#For authorities_contacted, we have many NaN values, I'll treat NaN as no authorities contacted and change the field to no authorities contacted\n",
    "\n",
    "df['authorities_contacted'] = df ['authorities_contacted'].fillna('No Authorities Contacted')\n",
    "\n",
    "#lets see if that worked\n",
    "print(df['authorities_contacted'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c579fb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
      "       'policy_state', 'policy_deductable', 'policy_annual_premium',\n",
      "       'umbrella_limit', 'insured_zip', 'insured_sex',\n",
      "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
      "       'insured_relationship', 'capital_gains', 'capital_loss',\n",
      "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
      "       'authorities_contacted', 'incident_state', 'incident_city',\n",
      "       'incident_location', 'incident_hour_of_the_day',\n",
      "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
      "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
      "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
      "       'auto_model', 'auto_year', 'fraud_reported', 'policy_csl_person',\n",
      "       'policy_csl_accident'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Lets now normalize the text fields by making them all lowercase\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace('-', '_').str.replace(' ', '_')\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60dd3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  incident_date  incident_year  incident_month  incident_day  \\\n",
      "0    2015-01-25           2015               1            25   \n",
      "1    2015-01-21           2015               1            21   \n",
      "2    2015-02-22           2015               2            22   \n",
      "3    2015-01-10           2015               1            10   \n",
      "4    2015-02-17           2015               2            17   \n",
      "\n",
      "   incident_dayofweek  \n",
      "0                   6  \n",
      "1                   2  \n",
      "2                   6  \n",
      "3                   5  \n",
      "4                   1  \n",
      "   incident_year  incident_month  incident_day  incident_dayofweek\n",
      "0           2015               1            25                   6\n",
      "1           2015               1            21                   2\n",
      "2           2015               2            22                   6\n",
      "3           2015               1            10                   5\n",
      "4           2015               2            17                   1\n"
     ]
    }
   ],
   "source": [
    "#now lets standarize common categorical columns\n",
    "\n",
    "cat_map = {\n",
    "    'y': 'Yes', 'yes': 'Yes', 'Y': 'Yes', 'YES': 'Yes',\n",
    "    'n': 'No', 'no': 'No', 'N': 'No', 'NO': 'No',\n",
    "    'Unknown': 'Unknown', '?': 'Unknown',\n",
    "    'none': 'None', 'None': 'None', 'NONE': 'None',\n",
    "\n",
    "}\n",
    "\n",
    "# Apply mapping to every value in every column that is string/object type\n",
    "for col in df.select_dtypes(include=\"object\"):\n",
    "    df[col] = df[col].replace(cat_map)\n",
    "\n",
    "\n",
    "#now lets start extracting date features\n",
    "# Convert 'incident_date' to datetime\n",
    "df['incident_date'] = pd.to_datetime(df['incident_date'], errors = 'coerce')\n",
    "\n",
    "# Extract date features\n",
    "df['incident_year'] = df['incident_date'].dt.year\n",
    "df['incident_month'] = df['incident_date'].dt.month\n",
    "df['incident_day'] = df['incident_date'].dt.day\n",
    "df['incident_dayofweek'] = df['incident_date'].dt.dayofweek # Monday=0, Sunday=6\n",
    "\n",
    "#Nows lets preview the new columns\n",
    "print(df[['incident_date', 'incident_year', 'incident_month', 'incident_day', 'incident_dayofweek']].head())\n",
    "\n",
    "#remove the original incident_date column\n",
    "df = df.drop(columns=['incident_date'])\n",
    "\n",
    "print(df[['incident_year', 'incident_month', 'incident_day', 'incident_dayofweek']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ea665a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['months_as_customer', 'age', 'policy_number', 'policy_deductable',\n",
      "       'policy_annual_premium', 'umbrella_limit', 'insured_zip',\n",
      "       'capital_gains', 'capital_loss', 'incident_hour_of_the_day',\n",
      "       'number_of_vehicles_involved', 'bodily_injuries', 'witnesses',\n",
      "       'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim',\n",
      "       'auto_year', 'policy_csl_person', 'policy_csl_accident'],\n",
      "      dtype='object')\n",
      "Index(['policy_bind_date', 'policy_state', 'insured_sex',\n",
      "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
      "       'insured_relationship', 'incident_type', 'collision_type',\n",
      "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
      "       'incident_city', 'incident_location', 'property_damage',\n",
      "       'police_report_available', 'auto_make', 'auto_model', 'fraud_reported'],\n",
      "      dtype='object')\n",
      "Overlap between numeric and object columns: set()\n"
     ]
    }
   ],
   "source": [
    "#ensure all numeric columns are of numeric type\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(numeric_cols)\n",
    "\n",
    "#lets check if any numeric columns are of object type\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "print(object_cols)\n",
    "\n",
    "#Any overlap?   \n",
    "overlap = set(numeric_cols).intersection(set(object_cols))\n",
    "print(\"Overlap between numeric and object columns:\", overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ff73c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discrepancies in total_claim_amount: 0\n"
     ]
    }
   ],
   "source": [
    "#lets check if total_claim_amount is equal to the sum of injury_claim, property_claim, and vehicle_claim\n",
    "df['calculated_total_claim'] = df['injury_claim'] + df['property_claim'] + df['vehicle_claim']\n",
    "discrepancies = df[df['total_claim_amount'] != df['calculated_total_claim']]\n",
    "print(\"Number of discrepancies in total_claim_amount:\", len(discrepancies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b05e80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, no missing values that we need to deal with here, or duplicate rows\n",
    "#We have already dealt with the negative value in the umbrella_limit column\n",
    "#We have also checked the capital-gains column for negative values and NaN values, and found none\n",
    "#We have also checked for duplicate rows and found none\n",
    "#We have also checked for missing values in the dataframe and found none that we need to deal with\n",
    "#We have also checked the authorities_contacted column for missing values and found none that we need to deal with\n",
    "\n",
    "#so next step is to save the cleaned dataframe to a new csv file\n",
    "df.to_csv('insurance_claims_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
