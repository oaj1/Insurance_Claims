# Insurance_Claims

Insurance_Claims_Load_Cleaning

    *Initial csv file is loaded
    *Initial data is evaluated
    *Data Cleaning techniques Deployed

Insurance_Claims_EDA
    *We will do some Python EDA, in addition to Tableau visualization
    *Python:
        *Descriptive stats (df.describe())
        *Fraud vs non-fraud frequency
        *Distributions of key variables (premium, deductible, capital gains/loss)
        *Correlations heatmap
        *Outliers (boxplots for numerical features)

    *Tableau
        *Highlight 4â€“5 of the most interesting relationships you found in Python.
        *Build dashboards that visually explain fraud risk factors.

    *****NOTE***** is this the stage where I would want to do more tableau than Python????

Insurance_Claims_Machine Learning
    *Here is where I'll start looking more into building models to predict fraud


DataSet: https://data.mendeley.com/datasets/992mh7dk9y/2


